{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIDHKgR9F8ZH",
        "outputId": "452db6ac-6f96-437d-d8f4-cc0554a0c5b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-XPi_e6Yd29wpx9mOCrTvesPTJ9ubgZZ\n",
            "To: /content/requirements.txt\n",
            "100% 68.0/68.0 [00:00<00:00, 54.5kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13rDhmuFjz3d1NWYm42n7I6pQsyieaazT\n",
            "To: /content/score_sentence_pairs.py\n",
            "100% 2.81k/2.81k [00:00<00:00, 3.75MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10GFDrB_C21PA1H7Hjq1SGmyjcD0QehuC\n",
            "To: /content/models.py\n",
            "100% 11.3k/11.3k [00:00<00:00, 18.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10BQYSlGu1CLjFUzFMtwuxgas_Qidjl6L\n",
            "To: /content/pairing.py\n",
            "100% 6.09k/6.09k [00:00<00:00, 10.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13_wkK7rsVgRlYmeoRYdxIT3-E_OJ0IOQ\n",
            "To: /content/utils.py\n",
            "100% 5.65k/5.65k [00:00<00:00, 5.26MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10ZDlZYoF6XCV8LIscnUVnfg2ZM9tTr-m\n",
            "To: /content/evaluate_sts.py\n",
            "100% 11.4k/11.4k [00:00<00:00, 9.84MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Vss9koo31QGnBr3BYbybe7hC9Ldk06s8\n",
            "To: /content/sent_pairs.txt\n",
            "100% 927/927 [00:00<00:00, 1.32MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19uy4-kXXDNYkvP2-Nj44imIosLKFNseE\n",
            "To: /content/paranmt.model\n",
            "100% 1.15M/1.15M [00:00<00:00, 76.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19sHUsvCM_gnHEC27q7ByC-RnV2V7UfL1\n",
            "To: /content/model.para.lc.100.pt\n",
            "100% 1.02G/1.02G [00:04<00:00, 212MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1-XPi_e6Yd29wpx9mOCrTvesPTJ9ubgZZ #requirements.txt\n",
        "!gdown --id 13rDhmuFjz3d1NWYm42n7I6pQsyieaazT #sent_score_pair.py\n",
        "!gdown --id 10GFDrB_C21PA1H7Hjq1SGmyjcD0QehuC #models.py\n",
        "!gdown --id 10BQYSlGu1CLjFUzFMtwuxgas_Qidjl6L #pairing.py\n",
        "!gdown --id 13_wkK7rsVgRlYmeoRYdxIT3-E_OJ0IOQ #utils.py\n",
        "!gdown --id 10ZDlZYoF6XCV8LIscnUVnfg2ZM9tTr-m #eval_sent.py\n",
        "!gdown --id 1Vss9koo31QGnBr3BYbybe7hC9Ldk06s8 #sent pair txt file\n",
        "!gdown --id 19uy4-kXXDNYkvP2-Nj44imIosLKFNseE #sentence piece model\n",
        "!gdown --id 19sHUsvCM_gnHEC27q7ByC-RnV2V7UfL1 # BERT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa5GdmgWIZvs",
        "outputId": "ab020aa7-efc9-40ff-a697-0169d161a56e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 2)) (1.10.0+cu111)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 4)) (0.0.46)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 5)) (0.1.96)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 6)) (0.42.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 7)) (1.19.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 8)) (3.2.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->-r /content/requirements.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r /content/requirements.txt (line 2)) (3.10.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r /content/requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r /content/requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r /content/requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r /content/requirements.txt (line 4)) (4.62.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r /content/requirements.txt (line 4)) (2019.12.20)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdDKV3QUIMjR",
        "outputId": "36a1709b-1d63-4b5a-ab43-1ac075b14733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Averaging(\n",
            "  (sim_loss): MarginRankingLoss()\n",
            "  (cosine): CosineSimilarity()\n",
            "  (embedding): Embedding(82983, 1024)\n",
            ")\n",
            "opical Imiquimod 5% Cream in the Treatment of Nodular Basal Cell Carcinoma After Initial Treatment With Curettage---after initiating treatment with the cuettage treatment, topical imiquimod 5% cream is used for the treatment of nodular basal cell carcinoma.\t0.9265482425689697\n",
            "opical Imiquimod 5% Cream in the Treatment of Nodular Basal Cell Carcinoma After Initial Treatment With Curettage---the topical imiquimod in the treatment of nodal basal cell following an initial treatment\t0.7626658082008362\n",
            "opical Imiquimod 5% Cream in the Treatment of Nodular Basal Cell Carcinoma After Initial Treatment With Curettage---after initiating treatment with the cuettage treatment is used for the treatment of nodular basal cell carcinoma.\t0.7700982689857483\n",
            "opical Imiquimod 5% Cream in the Treatment of Nodular Basal Cell Carcinoma After Initial Treatment With Curettage---after initiating with the cuettage treatment, topical imiquimod 5% cream is used for the treatment of cell carcinoma.\t0.8120404481887817\n"
          ]
        }
      ],
      "source": [
        "# !python -u score_sentence_pairs.py --sentence-pair-file /content/sent_pairs.txt --load-file /content/model.para.lc.100.pt  --sp-model /content/paranmt.model --gpu=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFtSPpL1GhkY",
        "outputId": "5188fc0a-1c3c-4944-b7a7-da1cd0f139a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Averaging(\n",
            "  (sim_loss): MarginRankingLoss()\n",
            "  (cosine): CosineSimilarity()\n",
            "  (embedding): Embedding(82983, 1024)\n",
            ")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Averaging(\n",
              "  (sim_loss): MarginRankingLoss()\n",
              "  (cosine): CosineSimilarity()\n",
              "  (embedding): Embedding(82983, 1024)\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import argparse\n",
        "from models import load_model\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--load-file\", default = \"/content/model.para.lc.100.pt\",help=\"path to saved model\")\n",
        "parser.add_argument(\"--sp-model\", default = \"/content/paranmt.model\",help=\"sentencepiece model to use\")\n",
        "parser.add_argument(\"--gpu\", default=1, type=int, help=\"whether to train on gpu\")\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "model, _ = load_model(None, args)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ka-R602vQpQL"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import numpy as np\n",
        "from sacremoses import MosesTokenizer\n",
        "from models import load_model\n",
        "from sacremoses import MosesTokenizer\n",
        "from utils import Example\n",
        "\n",
        "def cosine(u, v):\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
        "\n",
        "class FileSim:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.similarity = lambda s1, s2: np.nan_to_num(cosine(np.nan_to_num(s1), np.nan_to_num(s2)))\n",
        "\n",
        "    def score(self, params, batcher, s1, s2):\n",
        "        input1 = [s1]\n",
        "        input2 = [s2]\n",
        "        sys_scores = []\n",
        "        for ii in range(0, len(input1), params.batch_size):\n",
        "            batch1 = input1[ii:ii + params.batch_size]\n",
        "            batch2 = input2[ii:ii + params.batch_size]\n",
        "\n",
        "            # we assume get_batch already throws out the faulty ones\n",
        "            if len(batch1) == len(batch2) and len(batch1) > 0:\n",
        "                enc1 = batcher(params, batch1)\n",
        "                enc2 = batcher(params, batch2)\n",
        "\n",
        "                for kk in range(enc2.shape[0]):\n",
        "                    sys_score = self.similarity(enc1[kk], enc2[kk])\n",
        "                    sys_scores.append(sys_score)\n",
        "\n",
        "        return sys_scores\n",
        "\n",
        "def batcher(params, batch):\n",
        "    new_batch = []\n",
        "    for p in batch:\n",
        "        if params.tokenize:\n",
        "            tok = params.entok.tokenize(p, escape=False)\n",
        "            p = \" \".join(tok)\n",
        "        if params.lower_case:\n",
        "            p = p.lower()\n",
        "        p = params.sp.EncodeAsPieces(p)\n",
        "        p = \" \".join(p)\n",
        "        p = Example(p, params.lower_case)\n",
        "        p.populate_embeddings(params.model.vocab, params.model.zero_unk, params.model.ngrams)\n",
        "        new_batch.append(p)\n",
        "    x, l = params.model.torchify_batch(new_batch)\n",
        "    vecs = params.model.encode(x, l)\n",
        "    return vecs.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEtfjXleG5Cx"
      },
      "outputs": [],
      "source": [
        "def evaluate(args, model, s1, s2):\n",
        "\n",
        "    entok = MosesTokenizer(lang='en')\n",
        "\n",
        "    from argparse import Namespace\n",
        "\n",
        "    new_args = Namespace(batch_size=32, entok=entok, sp=model.sp,\n",
        "                     params=args, model=model, lower_case=model.args.lower_case,\n",
        "                     tokenize=model.args.tokenize)\n",
        "    \n",
        "    s = FileSim()\n",
        "    scores = s.score(new_args, batcher, s1, s2)\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtRoHOLXGptE",
        "outputId": "0eb395f5-70c7-4363-d694-398e23aeea70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.64013505]\n"
          ]
        }
      ],
      "source": [
        "print(evaluate(args, model, \"My cat.\", \"Stray cat.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIMeYX4DfgxI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Content_Presv_Inference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}